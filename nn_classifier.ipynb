{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43288ce0",
      "metadata": {},
      "source": [
        "<center><h2>ALTEGRAD Project</h2>\n",
        "\n",
        "<hr>\n",
        "<span style=\"font-variant: small-caps;\">Xavier Jim√©nez, Jean Quentin, Sacha Revol</span><br>\n",
        "<hr>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e3a9e1c-eaaf-41ec-bf6a-a10f02a696a7",
      "metadata": {
        "id": "4e3a9e1c-eaaf-41ec-bf6a-a10f02a696a7"
      },
      "source": [
        "# Classification from train/val data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27f5f04-c748-4fed-ae39-c430b9ed71a2",
      "metadata": {
        "id": "d27f5f04-c748-4fed-ae39-c430b9ed71a2"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37fbef5c-f772-4525-bbd1-0bd32a8ad063",
      "metadata": {
        "id": "37fbef5c-f772-4525-bbd1-0bd32a8ad063"
      },
      "outputs": [],
      "source": [
        "# XGboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Graphs\n",
        "import networkx as nx\n",
        "\n",
        "# Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K91jfLeKvJyd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K91jfLeKvJyd",
        "outputId": "230d799d-3943-4906-8496-0f3874b225c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j1KKONNzvQqk",
      "metadata": {
        "id": "j1KKONNzvQqk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/MVA/ALTEGRAD/Final Project/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "awoPFRsSvb1Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awoPFRsSvb1Y",
        "outputId": "05b20f58-f243-47dc-9ecf-9fda6008d0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abstract_embeddings.ipynb\t\t\tspecter.ipynb\n",
            "data\t\t\t\t\t\tsubmission.csv\n",
            "nn_classifier.ipynb\t\t\t\tX_test_edge_embeddings.npy\n",
            "sentence_transformer_abstract_embeddings.ipynb\tX_train_val_edge_embeddings.npy\n",
            "specter2.ipynb\t\t\t\t\tX_val_edge_embeddings.npy\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d2239b4-a8ff-4f0e-8947-27c0610fc75d",
      "metadata": {
        "id": "1d2239b4-a8ff-4f0e-8947-27c0610fc75d"
      },
      "source": [
        "## 2. Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a1aaee-cd42-4825-b791-1986276e53c5",
      "metadata": {
        "id": "a9a1aaee-cd42-4825-b791-1986276e53c5"
      },
      "source": [
        "### 2.1 Loading train/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e2f9e8-3cb6-4bf6-83a3-b9efa9808f93",
      "metadata": {
        "id": "12e2f9e8-3cb6-4bf6-83a3-b9efa9808f93"
      },
      "outputs": [],
      "source": [
        "#with open(\"data/training_data/X_val.npy\", \"rb\") as fp:   #Pickling\n",
        "with open(\"X_val_edge_embeddings.npy\", \"rb\") as fp:   #Pickling\n",
        "    X_val = np.load(fp)\n",
        "    X_val = X_val.astype('float32')\n",
        "\n",
        "with open(\"data/training_data/y_val.npy\", \"rb\") as fp:   #Pickling\n",
        "    y_val = np.load(fp)\n",
        "    #y_val = y_val.astype('float32')\n",
        "\n",
        "#with open(\"data/training_data/X_train_val.npy\", \"rb\") as fp:   #Pickling\n",
        "with open(\"X_train_val_edge_embeddings.npy\", \"rb\") as fp:   #Pickling\n",
        "    X_train_val = np.load(fp)\n",
        "    X_train_val = X_train_val.astype('float32')\n",
        "\n",
        "with open(\"data/training_data/y_train_val.npy\", \"rb\") as fp:   #Pickling\n",
        "    y_train_val = np.load(fp)\n",
        "    #y_train_val = y_train_val.astype('float32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96fffb1c-fa74-4e08-b7c5-1d40686cc212",
      "metadata": {
        "id": "96fffb1c-fa74-4e08-b7c5-1d40686cc212"
      },
      "source": [
        "## 3.Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fddc13e-4aa9-4b0d-9a07-2c34635237df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fddc13e-4aa9-4b0d-9a07-2c34635237df",
        "outputId": "42c770ed-4441-4527-a248-d109bf13cd35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69885, 1280)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00839cd-e224-424a-b420-36933add7b0e",
      "metadata": {
        "id": "c00839cd-e224-424a-b420-36933add7b0e"
      },
      "source": [
        "## 4. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48817bb8-34d0-4db1-9eb1-bba0d78b4f1a",
      "metadata": {
        "id": "48817bb8-34d0-4db1-9eb1-bba0d78b4f1a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, X_train, Y_train):\n",
        "        \n",
        "        #pos samples first\n",
        "        self.labels = Y_train\n",
        "        self.texts = X_train\n",
        "        \n",
        "\n",
        "        \n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print('getitem')\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2VVctStoud3",
      "metadata": {
        "id": "N2VVctStoud3"
      },
      "outputs": [],
      "source": [
        "full_x = np.concatenate((X_val, X_train_val), axis=0)\n",
        "full_y = np.concatenate((y_val, y_train_val), axis=0)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    full_x, full_y, test_size=0.05, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3cf5b2-f542-421d-8b50-3fb55c848947",
      "metadata": {
        "id": "8d3cf5b2-f542-421d-8b50-3fb55c848947"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data = Dataset(X_train_val, y_train_val)\n",
        "val_data = Dataset(X_val, y_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bc4ea1-08a9-45c1-b1bb-a3147acd1f6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86bc4ea1-08a9-45c1-b1bb-a3147acd1f6e",
        "outputId": "9757d22a-00a6-40ae-efe6-a15a7e412517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69885, 1280)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c913a822-c648-4713-bed7-bef0e4cafbd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "c913a822-c648-4713-bed7-bef0e4cafbd8",
        "outputId": "50d12d6c-5f19-4033-faf1-a792a6f0b63c"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm \n",
        "\n",
        "\n",
        "batch_size = 512\n",
        "#DataLoader\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "\n",
        "#defining the network\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,input_shape):\n",
        "        super(Net,self).__init__()\n",
        "        self.fc1 = nn.Linear(input_shape,640)\n",
        "        #self.fc2 = nn.Linear(1280, 640)\n",
        "        self.fc3 = nn.Linear(640, 320)\n",
        "        self.fc4 = nn.Linear(320,160)\n",
        "        self.fc5 = nn.Linear(160,80)\n",
        "        self.fc6 = nn.Linear(80,20)\n",
        "        self.fc7 = nn.Linear(20,1)\n",
        "        #self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        #x = self.dropout(x)\n",
        "        #x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = torch.relu(self.fc5(x))\n",
        "        x = torch.relu(self.fc6(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = torch.sigmoid(self.fc7(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "#hyper parameters\n",
        "epochs = 700\n",
        "# Model , Optimizer, Loss\n",
        "model = Net(input_shape=1280).double().to(\"cuda\")\n",
        "\n",
        "learning_rate = 0.0001\n",
        "learning_rates = [0.01, 0.005, 0.0001, 0.00005, 0.00001]\n",
        "\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#scheduler = LambdaLR(optimizer, lr_lambda=[0.02, 0.01])\n",
        "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=20,\n",
        " #                                             mode=\"triangular2\", cycle_momentum=False)\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "\n",
        "#forward loop\n",
        "losses = []\n",
        "accur = []\n",
        "losses_val = []\n",
        "accur_val = []\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "    #print(\"stepping!\")\n",
        "    #scheduler.step()\n",
        "\n",
        "    losses = []\n",
        "    accur = []\n",
        "    losses_val = []\n",
        "    accur_val = []\n",
        "\n",
        "    model.train()\n",
        "    for j,(x_train,y_train) in tqdm(enumerate(trainloader)):\n",
        "        \n",
        "        x_train = x_train.to(\"cuda\")\n",
        "        y_train = y_train.to(\"cuda\")\n",
        "        #calculate output\n",
        "        output = model(x_train.double())\n",
        "\n",
        "        #calculate loss\n",
        "        loss = loss_fn(output , y_train.reshape(-1,1).double())\n",
        "\n",
        "        #accuracy\n",
        "        preds = (output.squeeze().detach().round())# == y_train)#.sum()\n",
        "        acc = (torch.eq(preds, y_train).float().sum()/preds.shape[0]).item()\n",
        "        \n",
        "        losses.append(loss.item())\n",
        "        accur.append(acc)\n",
        "\n",
        "        #backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        for j,(x_test, y_test) in enumerate(test_loader):\n",
        "        \n",
        "                x_test = x_test.to(\"cuda\")\n",
        "                y_test = y_test.to(\"cuda\")\n",
        "\n",
        "                output = model(x_test.double())\n",
        "\n",
        "                #calculate loss\n",
        "                loss_val = loss_fn(output , y_test.reshape(-1,1).double())\n",
        "\n",
        "                #accuracy\n",
        "                preds = (output.squeeze().detach().round())# == y_train)#.sum()\n",
        "                acc_val = (torch.eq(preds, y_test).float().sum()/preds.shape[0]).item()\n",
        "\n",
        "                losses_val.append(loss_val.item())\n",
        "                accur_val.append(acc_val)\n",
        "\n",
        "    print(\"epoch {}\\t train_loss : {}\\t train_accuracy : {} \\t val_loss : {}\\t val_accuracy : {}\"\n",
        "          .format(i,\n",
        "                  round(sum(losses)/len(losses),4),\n",
        "                  round(sum(accur)/len(accur),4),\n",
        "                  round(sum(losses_val)/len(losses_val),4),\n",
        "                  round(sum(accur_val)/len(accur_val),4)))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a21d0f67",
      "metadata": {},
      "source": [
        "## 5. Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb0c1dc-9006-481d-b4c0-f9ecda822a12",
      "metadata": {
        "id": "dbb0c1dc-9006-481d-b4c0-f9ecda822a12"
      },
      "outputs": [],
      "source": [
        "with open(\"X_test_edge_embeddings.npy\", \"rb\") as fp:   #Pickling\n",
        "    X_test_final = np.load(fp)\n",
        "    X_test_final = X_test_final.astype('float32')\n",
        "\n",
        "test_data_final = Dataset(X_test_final, y_train_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a408a4b7-a695-4d26-97fe-b844bdc91bc6",
      "metadata": {
        "id": "a408a4b7-a695-4d26-97fe-b844bdc91bc6"
      },
      "outputs": [],
      "source": [
        "X_test_final = torch.Tensor(X_test_final)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z16lOo5sJ1Yz",
      "metadata": {
        "id": "z16lOo5sJ1Yz"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  output = model(X_test_final.to(\"cuda\").double())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e512650-d15a-422d-938e-8e4f0f218fc3",
      "metadata": {
        "id": "3e512650-d15a-422d-938e-8e4f0f218fc3"
      },
      "outputs": [],
      "source": [
        "result_final = output.detach().to(\"cpu\").numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XddmsCdpKWj4",
      "metadata": {
        "id": "XddmsCdpKWj4"
      },
      "outputs": [],
      "source": [
        "result_final = np.squeeze(result_final, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U34T3cyqKfEd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U34T3cyqKfEd",
        "outputId": "bda87e19-49dc-4b14-a7d4-86b8944699e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.99595408, 0.28561006, 0.97046264, ..., 0.05600482, 0.99826963,\n",
              "       0.61759439])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "485864e7-b5e7-49f0-9bcb-b9b5c12dc18e",
      "metadata": {
        "id": "485864e7-b5e7-49f0-9bcb-b9b5c12dc18e"
      },
      "outputs": [],
      "source": [
        "import csv \n",
        "\n",
        "predictions = zip(range(len(result_final)), result_final)\n",
        "with open(\"submission.csv\",\"w\") as pred:\n",
        "    csv_out = csv.writer(pred)\n",
        "    csv_out.writerow(['id','predicted'])\n",
        "    for row in predictions:\n",
        "        csv_out.writerow(row)\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "nn_classifier.ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "conda-env-altegrad2-py",
      "name": "common-cu110.m89",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cu110:m89"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
